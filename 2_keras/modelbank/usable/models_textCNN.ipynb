{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Concatenate, Flatten, Dropout, Dense\n",
    "from tensorflow.python.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.callbacks import History\n",
    "from lib.KerasHelpers.modelhelpers import model_placement\n",
    "from src.models.model import TextCNN\n",
    "from argparse import ArgumentParser\n",
    "import deepdish as dd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "    \n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential implementaion (mulit-label classification)\n",
    "\n",
    "def TextCNN():  \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(256,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextCNN()\n",
    "# model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chainwise implementation\n",
    "\n",
    "def TextCNN(MAX_SEQUENCE_LENGTH, EMBEDDING_DIM, num_classes, num_words, dropout_rate=0.4, flag='rand', embedding_weights=None):\n",
    "\n",
    "    x_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "    embedding_layer = Embedding(input_dim=num_words,\n",
    "                                output_dim=EMBEDDING_DIM,\n",
    "                                embeddings_initializer='uniform',\n",
    "                                input_length=MAX_SEQUENCE_LENGTH)\n",
    "    x = embedding_layer(x_input)\n",
    "\n",
    "    kernel_sizes = [3, 4, 5]\n",
    "    pooled = []\n",
    "\n",
    "    for kernel in kernel_sizes:\n",
    "\n",
    "        conv = Conv1D(filters=100,\n",
    "                      kernel_size=kernel,\n",
    "                      padding='valid',\n",
    "                      strides=1,\n",
    "                      kernel_initializer='he_uniform',\n",
    "                      activation='relu')(x)\n",
    "        \n",
    "        pool = MaxPooling1D(pool_size=MAX_SEQUENCE_LENGTH - kernel + 1)(conv)\n",
    "\n",
    "        pooled.append(pool)\n",
    "\n",
    "    merged = Concatenate(axis=-1)(pooled)\n",
    "\n",
    "    flatten = Flatten()(merged)\n",
    "\n",
    "    drop = Dropout(rate=dropout_rate)(flatten)\n",
    "    \n",
    "    x_output = Dense(num_classes, kernel_initializer='he_uniform', activation='softmax')(drop)\n",
    "\n",
    "    return Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = \n",
    "# (5000, 128)\n",
    "\n",
    "y_train = \n",
    "# (5000, 2)\n",
    "\n",
    "drop_rate = 0.2\n",
    "batch_size   = 32\n",
    "num_epochs   = 12\n",
    "lr = 0.001\n",
    "\n",
    "kwargs = {'MAX_SEQUENCE_LENGTH': x_train.shape[1],\n",
    "          'EMBEDDING_DIM': 300\n",
    "          'num_classes': y_train.shape[1],\n",
    "          'num_words': data_dict['num_words'],\n",
    "          'dropout_rate': dropout_rate,\n",
    "         }\n",
    "\n",
    "model = TextCNN(**kwargs)\n",
    "\n",
    "# model = model_placement(text_model, num_gpus=options.num_gpus)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=SGD(lr=lr))\n",
    "\n",
    "model.fit(x=x_train, y=y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=num_epochs, \n",
    "          validation_data=validation_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "congyuml",
   "language": "python",
   "name": "congyuml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
