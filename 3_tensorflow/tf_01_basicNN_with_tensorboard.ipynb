{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to build it with tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to carefully arrange our namescope\n",
    "# Then we put tf.summary.scalar or tf.summary.histogram where we need\n",
    "# Then we merge the summaries by: tf.summary.merge_all()\n",
    "# finally, during the sess, we sess.run the mergerd and write the output (smy) to writer:\n",
    "# how? by \n",
    "# writer = tf.summary.FileWriter('logs/', sess.graph) \n",
    "# and\n",
    "# writer.add_summary(smy, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summarises'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        \n",
    "        tf.summary.scalar('mean', mean)\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram',var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# 98% minist    \n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "    \n",
    "n_dim = 784\n",
    "n_out = 10\n",
    "        \n",
    "with tf.name_scope('input'):\n",
    "    with tf.name_scope('pic'):\n",
    "        x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "        \n",
    "    with tf.name_scope('label'):\n",
    "        y = tf.placeholder(tf.float32, [None, n_out])\n",
    "        \n",
    "# layer 1\n",
    "with tf.name_scope('layer_1'):\n",
    "    nb_n_1 = 500\n",
    "            \n",
    "    with tf.name_scope('weights'):  # inside namescope, the variable will get its appended name\n",
    "        w1 = tf.Variable(tf.truncated_normal([n_dim, nb_n_1], stddev = 0.1))\n",
    "        variable_summaries(w1)\n",
    "            \n",
    "    with tf.name_scope('bias'):\n",
    "        b1 = tf.Variable(tf.zeros([nb_n_1]) + 0.1)\n",
    "        variable_summaries(b1)\n",
    "            \n",
    "    a1 = tf.nn.tanh(tf.matmul(x, w1) + b1)\n",
    "    nb_n = nb_n_1\n",
    "       \n",
    "# layer 2\n",
    "with tf.name_scope('layer_2'):\n",
    "    nb_n_2 = 300\n",
    "    \n",
    "    with tf.name_scope('weights'):\n",
    "        w2 = tf.Variable(tf.truncated_normal([nb_n, nb_n_2], stddev = 0.1))\n",
    "        variable_summaries(w2)\n",
    "    \n",
    "    with tf.name_scope('bias'):\n",
    "        b2 = tf.Variable(tf.zeros([nb_n_2]) + 0.1)\n",
    "        variable_summaries(b2)\n",
    "    \n",
    "    a2 = tf.nn.tanh(tf.matmul(a1, w2) + b2)\n",
    "    nb_n = nb_n_2\n",
    "       \n",
    "# layer 3\n",
    "with tf.name_scope('layer_3'):\n",
    "    nb_n_3 = n_out\n",
    "    \n",
    "    with tf.name_scope('weights'):\n",
    "        w3 = tf.Variable(tf.truncated_normal([nb_n, nb_n_3], stddev = 0.1))\n",
    "        variable_summaries(w3)\n",
    "    \n",
    "    with tf.name_scope('bias'):\n",
    "        b3 = tf.Variable(tf.zeros([nb_n_3]) + 0.1)\n",
    "        variable_summaries(b3)\n",
    "        \n",
    "    a3 = tf.nn.softmax(tf.matmul(a2, w3) + b3)\n",
    "\n",
    "# model & train\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.square(y-a3))\n",
    "    # better : loss = -tf.reduce_mean(y * tf.log(a3)) * 1000.0\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "with tf.name_scope('optimizier'):\n",
    "    learning_rate =  tf.placeholder(tf.float32) \n",
    "    optimizer =  tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train = optimizer.minimize(loss) \n",
    "        \n",
    "\n",
    "# information\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_predict = tf.equal(tf.argmax(a3, 1), tf.argmax(y, 1)) \n",
    "    # argmax is biggest location\n",
    "    # this is a list of bool\n",
    "    \n",
    "    # tf.cast make True to be 1\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "init   = tf.initialize_all_variables()\n",
    "merged = tf.summary.merge_all()\n",
    "    \n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph) \n",
    "    sess.run(init)\n",
    "    n_epoch = 50\n",
    "    for epoch in range(n_epoch + 1):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            #  sess.run(train, feed_dict={x:batch_xs, y:batch_ys, learning_rate: 0.001 * (0.98**epoch)})\n",
    "            #  smy = sess.run(merged, feed_dict = {x:batch_xs, y:batch_ys, learning_rate: 0.001 * (0.98**epoch)})\n",
    "            \n",
    "            _,smy = sess.run([train, merged], feed_dict={x:batch_xs, y:batch_ys, learning_rate: 0.001 * (0.98**epoch)})\n",
    "            writer.add_summary(smy, epoch)\n",
    "            \n",
    "        if epoch % 2 == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "            print('{}%\\tIteration {} : accuracy : {}'.format(float(epoch)*100/n_epoch, epoch, acc))\n",
    "    \n",
    "tf.reset_default_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "congyuml",
   "language": "python",
   "name": "congyuml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
